FROM nvidia/cuda:11.7.1-runtime-ubuntu20.04

# Set timezone to avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Install system dependencies including FFmpeg development libraries
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libavcodec-dev \
    libavformat-dev \
    libavdevice-dev \
    libavutil-dev \
    libavfilter-dev \
    libswscale-dev \
    libswresample-dev \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    pkg-config \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Install Python dependencies with GPU support
RUN pip3 install --upgrade pip

# Install PyTorch with CUDA support (cached layer)
RUN pip3 install --no-cache-dir \
    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

# Pre-install av separately with extended timeout (most problematic package)
# This creates a separate cached Docker layer
RUN pip3 install --timeout=300 --retries=5 av==10.0.0

# Install stable dependencies (cached layer if av doesn't change)
RUN pip3 install --no-cache-dir \
    fastapi==0.104.1 \
    uvicorn==0.24.0 \
    python-multipart==0.0.6 \
    httpx==0.25.2 \
    pydantic==2.5.0 \
    numpy

# Install faster-whisper and audio processing libs (depends on av)
RUN pip3 install --no-cache-dir \
    --timeout=300 \
    --retries=5 \
    faster-whisper==0.9.0 \
    librosa

# Create models directory
RUN mkdir -p /app/models

# Copy service files
COPY . .

# Set environment variables for GPU
ENV CUDA_VISIBLE_DEVICES=0
ENV WHISPER_DEVICE=cuda
ENV WHISPER_COMPUTE_TYPE=float16

# Expose port
EXPOSE 8003

# Run the service
CMD ["uvicorn", "whisper_service:app", "--host", "0.0.0.0", "--port", "8003"] 