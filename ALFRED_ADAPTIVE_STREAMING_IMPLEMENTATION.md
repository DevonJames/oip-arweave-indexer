# ALFRED Adaptive Streaming Implementation

## üéØ Overview

This implementation upgrades ALFRED's voice capabilities with near-real-time adaptive streaming that achieves:
- **<300ms first-word latency** (bootstrap chunk optimization)
- **Continuous speech flow** with minimal buffering gaps  
- **Natural boundary chunking** (sentences, clauses, phrases)
- **Adaptive chunk sizing** based on LLM vs TTS speed ratios
- **Comprehensive diagnostics** and performance monitoring

## üèóÔ∏è Architecture

### Core Components

1. **AdaptiveChunking** (`helpers/adaptiveChunking.js`)
   - Manages real-time text segmentation with natural boundaries
   - Implements bootstrap chunk logic for immediate response
   - Dynamically adapts chunk sizes based on generation/synthesis speeds

2. **StreamingCoordinator** (`helpers/streamingCoordinator.js`)  
   - Coordinates LLM-TTS pipeline with rolling buffer system
   - Manages audio queue and timing for smooth playback
   - Handles concurrent TTS requests and session management

3. **Enhanced Generators** (`helpers/generators.js`)
   - New adaptive streaming functions integrated with existing system
   - Fallback compatibility with legacy chunked TTS
   - Support for multiple TTS engines (ElevenLabs, local services)

4. **Upgraded Voice Routes** (`routes/voice.js`)
   - Modified `/api/voice/converse` endpoint to use adaptive streaming
   - New diagnostics endpoint for monitoring performance
   - Graceful fallback to legacy system if adaptive streaming fails

## üöÄ Key Features

### Bootstrap Chunk System
- **Target**: First audio within 300ms of user input
- **Logic**: Send 8-15 words immediately when available OR timeout reached
- **Natural breaks**: Prefer sentence/phrase endings even in bootstrap

### Adaptive Chunk Sizing
```javascript
// Growth formula based on speed ratio
next_chunk_size = current_size * GROWTH_FACTOR
// Where GROWTH_FACTOR adjusts based on:
speed_ratio = LLM_generation_speed / TTS_synthesis_speed

// Speed ratio > 1.2: LLM faster ‚Üí increase chunks  
// Speed ratio < 0.8: TTS faster ‚Üí decrease chunks
// Speed ratio 0.8-1.2: balanced ‚Üí maintain size
```

### Natural Boundary Detection
Priority order for chunk breaks:
1. **Sentence endings**: `.!?`
2. **Strong punctuation**: `;:`  
3. **Comma breaks**: `,`
4. **Clause breaks**: `and`, `but`, `however`, etc.
5. **Natural pauses**: `after`, `while`, `because`, etc.

### Rolling Buffer System
- **Pipelined execution**: While Chunk N plays, Chunk N+1 generates
- **Queue management**: Max 5 chunks in audio queue
- **Timing coordination**: <100ms delay between chunk transitions
- **Concurrent limits**: Max 3 simultaneous TTS requests

## üìä Performance Metrics

The system tracks comprehensive diagnostics:

```javascript
{
  // Latency metrics
  firstAudioLatency: 280,        // ms to first audio
  sessionDuration: 12500,        // total session time
  
  // Quality metrics  
  chunksGenerated: 8,            // total chunks processed
  naturalBreakRate: 0.875,       // % of natural vs forced breaks
  ttsFailures: 0,                // failed TTS requests
  
  // Adaptive metrics
  currentChunkSize: 320,         // current adaptive size
  generationSpeed: 4.2,          // words/second from LLM
  synthesisSpeed: 3.0,           // words/second TTS playback
  
  // Pipeline health
  queueSize: 1,                  // current audio queue size
  activeTTSRequests: 2           // concurrent TTS calls
}
```

## üîß API Changes

### Enhanced `/api/voice/converse` Endpoint
- **Backward compatible**: Existing clients continue to work
- **New features**: Adaptive streaming with fallback to legacy system
- **Enhanced responses**: Include adaptive streaming metrics

### New Diagnostics Endpoint
```
GET /api/voice/adaptive-diagnostics/:sessionId
```
Returns real-time performance metrics for active sessions.

## üéõÔ∏è Configuration Options

### Voice Configuration
```javascript
const voiceConfig = {
  engine: 'elevenlabs',           // TTS engine selection
  voiceId: 'voice-id-here',       // Voice identifier
  targetLatency: 300,             // First-word latency target (ms)
  maxChunkSize: 800,              // Maximum chunk size (chars)
  speechRate: 3.0                 // Expected speech rate (words/sec)
};
```

### Environment Variables
```bash
# TTS Service Configuration
TTS_SERVICE_URL=http://localhost:5002
ELEVENLABS_API_KEY=your-key-here

# Adaptive Streaming Settings
ADAPTIVE_STREAMING_ENABLED=true
BOOTSTRAP_TIMEOUT=300
MAX_CONCURRENT_TTS=3
```

## üß™ Testing Guide

### 1. Basic Functionality Test
```bash
# Start a voice conversation
curl -X POST http://localhost:3000/api/voice/converse \
  -F "audio=@test-audio.wav" \
  -F "voiceConfig={\"engine\":\"elevenlabs\",\"voiceId\":\"test-voice\"}"

# Monitor the SSE stream
curl http://localhost:3000/api/voice/open-stream?dialogueId=your-dialogue-id
```

### 2. Latency Measurement
```javascript
// Client-side timing measurement
const startTime = Date.now();
// ... send request ...
// On first audio chunk received:
const firstAudioLatency = Date.now() - startTime;
console.log(`First audio latency: ${firstAudioLatency}ms`);
```

### 3. Diagnostics Monitoring
```bash
# Get session diagnostics
curl http://localhost:3000/api/voice/adaptive-diagnostics/your-session-id

# Expected response with performance metrics
{
  "success": true,
  "diagnostics": {
    "firstAudioLatency": 280,
    "naturalBreakRate": 0.875,
    "chunksGenerated": 8,
    // ... more metrics
  }
}
```

### 4. Stress Testing
```javascript
// Multiple concurrent sessions
const sessions = [];
for (let i = 0; i < 5; i++) {
  sessions.push(startVoiceSession(`session-${i}`));
}

// Monitor performance degradation
await Promise.all(sessions);
```

## üîÑ Fallback Behavior

The system includes robust fallback mechanisms:

1. **Adaptive ‚Üí Legacy TTS**: If StreamingCoordinator fails
2. **ElevenLabs ‚Üí Local TTS**: If cloud service unavailable  
3. **Chunked ‚Üí Simple TTS**: If all streaming methods fail
4. **Graceful degradation**: Always attempt to provide audio response

## üìà Performance Expectations

### Target Metrics
- **First-word latency**: <300ms (target: 250ms)
- **Chunk transition delay**: <100ms
- **Natural break rate**: >80%
- **TTS failure rate**: <5%
- **Session success rate**: >95%

### Optimization Tips
1. **Use ElevenLabs Turbo**: Fastest high-quality TTS
2. **Tune chunk sizes**: Balance latency vs quality
3. **Monitor diagnostics**: Watch for bottlenecks
4. **Adjust concurrency**: Based on hardware capabilities

## üö® Troubleshooting

### Common Issues

**High first-word latency (>500ms)**
- Check TTS service response times
- Verify network connectivity
- Consider reducing bootstrap timeout

**Choppy audio playback**
- Increase chunk overlap buffer
- Check client audio queue management  
- Monitor TTS generation vs playback speed

**Frequent fallbacks to legacy system**
- Check StreamingCoordinator logs
- Verify AdaptiveChunking configuration
- Test TTS service availability

### Debug Logging
```javascript
// Enable detailed logging
process.env.DEBUG_ADAPTIVE_STREAMING = 'true';

// Monitor specific components
console.log('[AdaptiveChunking] chunk ready:', chunkData);
console.log('[StreamingCoordinator] session metrics:', metrics);
```

## üîÆ Future Enhancements

1. **Voice Activity Detection (VAD)**: Better interrupt handling
2. **Prosody Analysis**: Smarter chunk boundary detection
3. **Client-side Buffering**: Predictive audio caching
4. **ML-based Optimization**: Learning optimal chunk sizes
5. **Multi-language Support**: Language-specific chunking rules

## üìù Implementation Summary

This adaptive streaming system represents a significant upgrade to ALFRED's voice capabilities, providing near-real-time speech synthesis with intelligent chunking and comprehensive performance monitoring. The implementation maintains backward compatibility while offering substantial improvements in perceived latency and speech quality.

The system is production-ready with robust error handling, comprehensive diagnostics, and graceful fallback mechanisms to ensure reliable operation even under adverse conditions.
