/**
 * Notes API Routes
 * Handles Alfred Meeting Notes endpoints for audio ingestion, retrieval, and management
 */
const express = require('express');
const multer = require('multer');
const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const { authenticateToken } = require('../helpers/utils');
const { getRecords, searchRecordInDB } = require('../helpers/elasticsearch');
const { getSTTService } = require('../services/sttService');
const { getSummarizationService } = require('../services/summarizationService');
const { getChunkingService } = require('../services/chunkingService');
const { getNotesRecordsService } = require('../services/notesRecordsService');

const router = express.Router();

// Configure multer for file uploads
const uploadDir = path.join(__dirname, '../data/temp/notes');
if (!fs.existsSync(uploadDir)) {
    fs.mkdirSync(uploadDir, { recursive: true });
}

const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        cb(null, uploadDir);
    },
    filename: (req, file, cb) => {
        const uniqueName = `audio_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        cb(null, uniqueName);
    }
});

const upload = multer({
    storage,
    limits: {
        fileSize: 500 * 1024 * 1024 // 500MB limit
    }
});

/**
 * POST /api/notes/from-audio
 * Main ingestion endpoint for audio notes
 * Processes: Audio â†’ Transcription â†’ Chunking â†’ Summary â†’ OIP Records
 */
router.post('/from-audio', authenticateToken, upload.single('audio'), async (req, res) => {
    let tempFilePath = null;
    
    try {
        console.log('ðŸŽ™ï¸ [POST /api/notes/from-audio] Starting audio note ingestion');
        console.log('ðŸ“‹ [Request] User:', req.user.email);
        console.log('ðŸ“‹ [Request] File:', req.file ? req.file.originalname : 'none');
        console.log('ðŸ“‹ [Request] Body:', Object.keys(req.body));

        // ========================================
        // STEP 1: Validate Request
        // ========================================
        // Either audio file OR transcript must be provided
        const hasAudioFile = !!req.file;
        const hasTranscript = !!req.body.transcript;
        
        if (!hasAudioFile && !hasTranscript) {
            return res.status(400).json({
                success: false,
                error: 'Either audio file or transcript must be provided'
            });
        }
        
        if (hasTranscript && !hasAudioFile) {
            console.log('ðŸ“ [Step 1] Transcript provided without audio file (text-only mode)');
        }

        const {
            start_time,
            end_time,
            note_type,
            device_type,
            capture_location,
            transcription_engine_id,
            transcript, // Optional: Pre-existing transcript to skip speech-to-text
            chunking_strategy = 'BY_TIME_30S',
            participant_display_names,
            participant_roles,
            calendar_event_id,
            calendar_start_time,
            calendar_end_time,
            model = 'parallel', // LLM model selection (supports 'parallel', 'gpt-4o-mini', 'grok-beta', etc.)
            addToWebServer = 'false',
            addToBitTorrent = 'false',
            addToIPFS = 'false'
        } = req.body;

        // Validate required fields
        if (!start_time || !end_time) {
            return res.status(400).json({
                success: false,
                error: 'Missing required fields: start_time and end_time'
            });
        }

        if (!note_type) {
            return res.status(400).json({
                success: false,
                error: 'Missing required field: note_type'
            });
        }

        if (!device_type) {
            return res.status(400).json({
                success: false,
                error: 'Missing required field: device_type'
            });
        }

        // Validate note_type
        const validNoteTypes = ['MEETING', 'ONE_ON_ONE', 'STANDUP', 'IDEA', 'REFLECTION', 'INTERVIEW', 'OTHER'];
        if (!validNoteTypes.includes(note_type)) {
            return res.status(400).json({
                success: false,
                error: `Invalid note_type. Must be one of: ${validNoteTypes.join(', ')}`
            });
        }

        // Validate device_type
        const validDeviceTypes = ['IPHONE', 'MAC', 'WATCH', 'OTHER'];
        if (!validDeviceTypes.includes(device_type)) {
            return res.status(400).json({
                success: false,
                error: `Invalid device_type. Must be one of: ${validDeviceTypes.join(', ')}`
            });
        }

        // Validate time range
        const startDate = new Date(start_time);
        const endDate = new Date(end_time);
        if (startDate >= endDate) {
            return res.status(400).json({
                success: false,
                error: 'start_time must be before end_time'
            });
        }

        // Validate chunking strategy
        const chunkingService = getChunkingService();
        if (!chunkingService.isValidStrategy(chunking_strategy)) {
            return res.status(400).json({
                success: false,
                error: `Invalid chunking_strategy. Must be one of: BY_TIME_15S, BY_TIME_30S, BY_TIME_60S, BY_SENTENCE, BY_PARAGRAPH, BY_SPEAKER`
            });
        }

        // Parse participant arrays if provided
        let participantNames = [];
        let participantRolesArray = [];
        if (participant_display_names) {
            try {
                participantNames = JSON.parse(participant_display_names);
            } catch (e) {
                participantNames = [participant_display_names];
            }
        }
        if (participant_roles) {
            try {
                participantRolesArray = JSON.parse(participant_roles);
            } catch (e) {
                participantRolesArray = [participant_roles];
            }
        }

        // Validate participant arrays have same length if both provided
        if (participantNames.length > 0 && participantRolesArray.length > 0) {
            if (participantNames.length !== participantRolesArray.length) {
                return res.status(400).json({
                    success: false,
                    error: 'participant_display_names and participant_roles must have same length'
                });
            }
        }

        if (hasAudioFile) {
            tempFilePath = req.file.path;
        }
        const userPublicKey = req.user.publicKey || req.user.publisherPubKey;
        const token = req.headers.authorization.split(' ')[1];

        if (!userPublicKey) {
            return res.status(401).json({
                success: false,
                error: 'User public key not available'
            });
        }

        // ========================================
        // STEP 2: Upload Audio File via /api/media/upload (Skip if no audio)
        // ========================================
        let audioBuffer, audioSize, audioHash, durationSec;
        
        if (hasAudioFile) {
            console.log('ðŸ“¼ [Step 2] Uploading audio file...');
            
            audioBuffer = fs.readFileSync(tempFilePath);
            audioSize = audioBuffer.length;
            audioHash = crypto.createHash('sha256').update(audioBuffer).digest('hex');
            durationSec = Math.round((endDate - startDate) / 1000);
        } else {
            console.log('ðŸ“ [Step 2] No audio file, skipping upload...');
            durationSec = Math.round((endDate - startDate) / 1000);
        }

        const notesRecordsService = getNotesRecordsService();
        
        let audioMeta = null;
        
        if (hasAudioFile) {
            // Parse boolean params
            const shouldAddToWebServer = addToWebServer === 'true' || addToWebServer === true;
            const shouldAddToBitTorrent = addToBitTorrent === 'true' || addToBitTorrent === true;
            const shouldAddToIPFS = addToIPFS === 'true' || addToIPFS === true;

            console.log(`ðŸ“¤ [Step 2] Storage options: WebServer=${shouldAddToWebServer}, BitTorrent=${shouldAddToBitTorrent}, IPFS=${shouldAddToIPFS}`);

            audioMeta = {
                audioHash,
                durationSec,
                audioCodec: router._detectCodecFromMime(req.file.mimetype),
                contentType: req.file.mimetype,
                size: audioSize,
                filename: req.file.originalname || `note_audio_${Date.now()}.${router._getExtensionFromMime(req.file.mimetype)}`,
                webUrl: null,
                arweaveAddress: null,
                ipfsAddress: null,
                bittorrentAddress: null,
                magnetURI: null
            };
            
            // Upload audio file using /api/media/upload endpoint
            try {
            const FormData = require('form-data');
            const uploadForm = new FormData();
            uploadForm.append('file', audioBuffer, {
                filename: audioMeta.filename,
                contentType: req.file.mimetype
            });
            uploadForm.append('access_level', 'private');

            const axios = require('axios');
            const uploadResponse = await axios.post(
                `http://localhost:${process.env.PORT || 3005}/api/media/upload`,
                uploadForm,
                {
                    headers: {
                        ...uploadForm.getHeaders(),
                        'Authorization': `Bearer ${token}`
                    },
                    timeout: 60000
                }
            );

            if (uploadResponse.data && uploadResponse.data.success) {
                const mediaId = uploadResponse.data.mediaId;
                audioMeta.mediaId = mediaId;
                audioMeta.httpUrl = uploadResponse.data.httpUrl;
                audioMeta.bittorrentAddress = uploadResponse.data.magnetURI;
                audioMeta.magnetURI = uploadResponse.data.magnetURI;
                console.log('âœ… [Step 2] Audio uploaded to media server:', mediaId);

                // Web server setup if requested
                if (shouldAddToWebServer) {
                    try {
                        const webSetupResponse = await axios.post(
                            `http://localhost:${process.env.PORT || 3005}/api/media/web-setup`,
                            {
                                mediaId: mediaId,
                                filename: audioMeta.filename
                            },
                            {
                                headers: { 'Authorization': `Bearer ${token}` },
                                timeout: 30000
                            }
                        );
                        if (webSetupResponse.data && webSetupResponse.data.success) {
                            audioMeta.webUrl = webSetupResponse.data.webUrl;
                            console.log('âœ… [Step 2] Audio web URL configured:', audioMeta.webUrl);
                        }
                    } catch (webError) {
                        console.warn('âš ï¸ [Step 2] Web setup failed (non-fatal):', webError.message);
                    }
                }

                // IPFS upload if requested
                if (shouldAddToIPFS) {
                    try {
                        const ipfsResponse = await axios.post(
                            `http://localhost:${process.env.PORT || 3005}/api/media/ipfs-upload`,
                            { mediaId: mediaId },
                            {
                                headers: { 'Authorization': `Bearer ${token}` },
                                timeout: 120000
                            }
                        );
                        if (ipfsResponse.data && ipfsResponse.data.success) {
                            audioMeta.ipfsAddress = ipfsResponse.data.ipfsHash;
                            console.log('âœ… [Step 2] Audio uploaded to IPFS:', audioMeta.ipfsAddress);
                        }
                    } catch (ipfsError) {
                        console.warn('âš ï¸ [Step 2] IPFS upload failed (non-fatal):', ipfsError.message);
                    }
                }
            }
            } catch (uploadError) {
                console.warn('âš ï¸ [Step 2] Media upload failed (continuing with basic metadata):', uploadError.message);
            }
        } // End if (hasAudioFile)

        // ========================================
        // STEP 3: Resolve Transcription Engine (Skip if transcript provided)
        // ========================================
        let transcriptionEngineRecord = null;
        let transcriptionEngineDid = null;
        
        if (transcript) {
            console.log('ðŸ“ [Step 3] Transcript provided, skipping transcription engine resolution');
        } else {
            console.log('ðŸ” [Step 3] Resolving transcription engine...');
            
            if (transcription_engine_id) {
                try {
                    const engineResults = await getRecords({
                        recordType: 'transcriptionEngine',
                        fieldName: 'transcriptionEngine.engine_id',
                        fieldSearch: transcription_engine_id,
                        fieldMatchMode: 'exact',
                        limit: 1
                    });

                    if (engineResults.records && engineResults.records.length > 0) {
                        transcriptionEngineRecord = engineResults.records[0];
                        transcriptionEngineDid = transcriptionEngineRecord.oip?.did || transcriptionEngineRecord.oip?.didTx;
                        console.log('âœ… [Step 3] Found transcription engine:', transcription_engine_id);
                    } else {
                        console.warn('âš ï¸ [Step 3] Transcription engine not found:', transcription_engine_id);
                        return res.status(422).json({
                            success: false,
                            error: `Transcription engine not configured: ${transcription_engine_id}`
                        });
                    }
                } catch (error) {
                    console.error('âŒ [Step 3] Engine lookup failed:', error.message);
                    return res.status(500).json({
                        success: false,
                        error: 'Failed to lookup transcription engine'
                    });
                }
            }
        }

        // ========================================
        // STEP 4: Run Speech-to-Text (Skip if transcript provided)
        // ========================================
        let transcriptionResult;
        
        if (transcript) {
            console.log('ðŸ“ [Step 4] Using provided transcript, skipping speech-to-text...');
            console.log(`   Text length: ${transcript.length} chars`);
            
            // Create a transcriptionResult object compatible with the rest of the flow
            transcriptionResult = {
                text: transcript,
                language: 'en', // Default to English when transcript is provided
                segments: [] // Empty segments array when using pre-existing transcript
            };
            
            console.log('âœ… [Step 4] Transcript ready');
        } else {
            console.log('ðŸŽ¤ [Step 4] Running speech-to-text...');
            
            const sttService = getSTTService();
            
            try {
                transcriptionResult = await sttService.transcribe(tempFilePath, transcriptionEngineRecord);
                console.log('âœ… [Step 4] Transcription complete');
                console.log(`   Language: ${transcriptionResult.language}`);
                console.log(`   Text length: ${transcriptionResult.text.length} chars`);
                console.log(`   Segments: ${transcriptionResult.segments.length}`);
            } catch (error) {
                console.error('âŒ [Step 4] Transcription failed:', error.message);
                return res.status(502).json({
                    success: false,
                    error: 'Speech-to-text processing failed',
                    details: error.message
                });
            }
        }

        // ========================================
        // STEP 5: Compute Note Hash
        // ========================================
        console.log('ðŸ” [Step 5] Computing note hash...');
        
        const noteHash = notesRecordsService.computeNoteHash(transcriptionResult.text);
        console.log(`âœ… [Step 5] Note hash: ${noteHash.substring(0, 16)}...`);

        // ========================================
        // STEP 6: Chunk Transcript
        // ========================================
        console.log('ðŸ“¦ [Step 6] Chunking transcript...');
        
        const chunks = chunkingService.chunk({
            segments: transcriptionResult.segments,
            strategy: chunking_strategy,
            fullText: transcriptionResult.text
        });
        
        console.log(`âœ… [Step 6] Created ${chunks.length} chunks`);

        // ========================================
        // STEP 7: Create Transcript Text Record
        // ========================================
        console.log('ðŸ“„ [Step 7] Creating transcript text record...');
        
        let transcriptTextDid = null;
        try {
            const transcriptRecord = await notesRecordsService.createTranscriptTextRecord(
                noteHash,
                transcriptionResult.text,
                transcriptionResult.language,
                userPublicKey,
                token
            );
            transcriptTextDid = transcriptRecord.did;
            console.log('âœ… [Step 7] Transcript record created:', transcriptTextDid);
        } catch (error) {
            console.error('âŒ [Step 7] Transcript record creation failed:', error.message);
            // Continue - not fatal
        }

        // ========================================
        // STEP 8: Generate Summary with LLM-based Tags
        // ========================================
        console.log(`ðŸ“ [Step 8] Generating summary with model: ${model}...`);
        
        const summarizationService = getSummarizationService();
        let summary;
        
        try {
            summary = await summarizationService.summarize({
                text: transcriptionResult.text,
                note_type: note_type,
                participants: participantNames,
                calendar: calendar_event_id ? {
                    calendar_event_id,
                    calendar_start_time,
                    calendar_end_time
                } : null,
                model: model
            });
            console.log('âœ… [Step 8] Summary generated');
            console.log(`   Key points: ${summary.key_points.length}`);
            console.log(`   Decisions: ${summary.decisions.length}`);
            console.log(`   Action items: ${summary.action_items.length}`);
            console.log(`   Topics: ${summary.topics.length}`);
            console.log(`   Keywords: ${summary.keywords.length}`);
            console.log(`   Tags: ${summary.tags.length}`);
        } catch (error) {
            console.error('âŒ [Step 8] Summarization failed:', error.message);
            // Continue with empty summary
            summary = {
                key_points: [],
                decisions: [],
                action_items: [],
                open_questions: [],
                sentiment_overall: 'NEUTRAL',
                topics: [],
                keywords: [],
                tags: []
            };
        }

        // ========================================
        // STEP 9: Generate Tags for Chunks & Create Records
        // ========================================
        console.log(`ðŸ—‚ï¸ [Step 9] Generating tags for ${chunks.length} chunks...`);
        
        // Generate tags for each chunk in parallel
        const chunkTagPromises = chunks.map(chunk => 
            summarizationService.generateChunkTags(chunk.text, note_type, model)
        );
        const chunkTags = await Promise.all(chunkTagPromises);
        
        // Attach tags to chunks
        chunks.forEach((chunk, index) => {
            chunk.tags = chunkTags[index] || [];
        });
        
        console.log('âœ… [Step 9] Chunk tags generated');

        // ========================================
        // STEP 10: Create Notes Record (before chunks so they can reference it)
        // ========================================
        console.log('ðŸ“‹ [Step 10] Creating main note record...');
        
        // Extract action item fields for parallel arrays
        const actionItemTexts = summary.action_items.map(item => item.text || '');
        const actionItemAssignees = summary.action_items.map(item => item.assignee || 'unassigned');
        const actionItemDueDates = summary.action_items.map(item => item.due_text || 'no date');

        // Use only LLM-generated tags
        const noteTags = summary.tags || [];

        const notePayload = {
            title: router._generateNoteTitle(note_type, participantNames, transcriptionResult.text),
            description: 'Alfred Notes capture',
            language: transcriptionResult.language,
            tags: noteTags,
            note_type,
            created_at: start_time,
            ended_at: end_time,
            device_type,
            capture_location,
            transcription_engine_did: transcriptionEngineDid,
            transcription_status: 'COMPLETE',
            transcript_did: transcriptTextDid,
            audio_ref: null, // Will be populated with audio DID if created
            audio_meta: audioMeta, // Store audio metadata
            summary_key_points: summary.key_points,
            summary_decisions: summary.decisions,
            summary_action_item_texts: actionItemTexts,
            summary_action_item_assignees: actionItemAssignees,
            summary_action_item_due_texts: actionItemDueDates,
            summary_open_questions: summary.open_questions,
            sentiment_overall: summary.sentiment_overall,
            topics_auto: summary.topics,
            keywords_auto: summary.keywords,
            participant_display_names: participantNames,
            participant_roles: participantRolesArray,
            calendar_event_id,
            calendar_start_time,
            calendar_end_time,
            chunking_strategy,
            chunk_count: chunks.length,
            chunk_ids: [] // Will be populated after chunks are created
        };

        let noteRecordDid = null;
        try {
            const noteRecord = await notesRecordsService.createNoteRecord(
                noteHash,
                notePayload,
                userPublicKey,
                token
            );
            noteRecordDid = noteRecord.did;
            console.log('âœ… [Step 10] Note record created:', noteRecordDid);
        } catch (error) {
            console.error('âŒ [Step 10] Note record creation failed:', error.message);
            return res.status(500).json({
                success: false,
                error: 'Failed to create note record',
                details: error.message
            });
        }

        // ========================================
        // STEP 11: Create Note Chunk Records (with note_ref)
        // ========================================
        console.log(`ðŸ—‚ï¸ [Step 11] Creating note chunk records with note reference...`);
        
        const captureDate = new Date(start_time).getTime();
        const chunkResults = await notesRecordsService.createAllNoteChunks(
            noteHash,
            chunks,
            note_type,
            captureDate,
            userPublicKey,
            token,
            noteRecordDid // Pass note DID so chunks can reference it
        );
        
        // Extract chunk DIDs
        const chunkDids = chunkResults.map(chunk => chunk.did);
        
        console.log(`âœ… [Step 11] Created ${chunkResults.length} chunk records`);

        // Update note record with chunk_ids by re-publishing
        try {
            await notesRecordsService.updateNoteChunkIds(
                noteHash,
                notePayload,
                chunkDids,
                userPublicKey,
                token
            );
            console.log('âœ… [Step 11] Note re-published with chunk IDs');
        } catch (error) {
            console.warn('âš ï¸ [Step 11] Failed to update note with chunk IDs (non-fatal):', error.message);
        }

        // ========================================
        // STEP 12: Cleanup & Return Response
        // ========================================
        console.log('ðŸ§¹ [Step 12] Cleaning up...');
        
        // Delete temporary audio file
        if (tempFilePath && fs.existsSync(tempFilePath)) {
            fs.unlinkSync(tempFilePath);
            console.log('âœ… [Step 12] Temporary file deleted');
        }

        // Return success response
        console.log('âœ… [POST /api/notes/from-audio] Ingestion complete');
        res.status(200).json({
            success: true,
            noteHash: noteHash,
            noteDid: noteRecordDid,
            transcriptionStatus: 'COMPLETE',
            chunkCount: chunks.length,
            summary: {
                keyPoints: summary.key_points.length,
                decisions: summary.decisions.length,
                actionItems: summary.action_items.length,
                openQuestions: summary.open_questions.length
            }
        });

    } catch (error) {
        console.error('âŒ [POST /api/notes/from-audio] Fatal error:', error);
        
        // Cleanup temp file on error
        if (tempFilePath && fs.existsSync(tempFilePath)) {
            try {
                fs.unlinkSync(tempFilePath);
            } catch (cleanupError) {
                console.warn('âš ï¸ Failed to cleanup temp file:', cleanupError.message);
            }
        }

        res.status(500).json({
            success: false,
            error: 'Audio note ingestion failed',
            details: error.message
        });
    }
});

/**
 * GET /api/notes/:noteHash
 * Get single note with all related data
 */
router.get('/:noteHash', authenticateToken, async (req, res) => {
    try {
        const { noteHash } = req.params;
        const userPublicKey = req.user.publicKey || req.user.publisherPubKey;

        console.log(`ðŸ“– [GET /api/notes/${noteHash}] Fetching note`);

        // Get main note record
        const noteResults = await getRecords({
            source: 'gun',
            recordType: 'notes',
            did: `did:gun:${userPublicKey.substring(0, 12)}:${noteHash}`,
            limit: 1,
            user: req.user,
            isAuthenticated: true
        });

        if (!noteResults.records || noteResults.records.length === 0) {
            return res.status(404).json({
                success: false,
                error: 'Note not found'
            });
        }

        const note = noteResults.records[0];

        // Get transcript text if available
        let transcript = null;
        if (note.data?.notes?.transcript_full_text) {
            try {
                const transcriptResults = await getRecords({
                    source: 'gun',
                    did: note.data.notes.transcript_full_text,
                    limit: 1,
                    user: req.user,
                    isAuthenticated: true
                });
                if (transcriptResults.records && transcriptResults.records.length > 0) {
                    transcript = transcriptResults.records[0];
                }
            } catch (error) {
                console.warn('âš ï¸ Failed to fetch transcript:', error.message);
            }
        }

        // Get chunks metadata (summary only, not full text)
        const chunkCount = note.data?.notes?.chunk_count || 0;
        const chunksInfo = {
            count: chunkCount,
            strategy: note.data?.notes?.chunking_strategy || 'BY_TIME_30S'
        };

        res.status(200).json({
            success: true,
            note: note,
            transcript: transcript,
            chunks: chunksInfo
        });

    } catch (error) {
        console.error('âŒ [GET /api/notes/:noteHash] Error:', error);
        res.status(500).json({
            success: false,
            error: 'Failed to retrieve note'
        });
    }
});

/**
 * GET /api/notes
 * List and search notes
 */
router.get('/', authenticateToken, async (req, res) => {
    try {
        const {
            note_type,
            from,
            to,
            search,
            limit = 20,
            page = 1,
            sortBy = 'date:desc'
        } = req.query;

        console.log('ðŸ“š [GET /api/notes] Listing notes');

        const queryParams = {
            source: 'gun',
            recordType: 'notes',
            limit: parseInt(limit),
            page: parseInt(page),
            sortBy: sortBy,
            user: req.user,
            isAuthenticated: true
        };

        // Add filters
        if (note_type) {
            queryParams.fieldName = 'notes.note_type';
            queryParams.fieldSearch = note_type;
            queryParams.fieldMatchMode = 'exact';
        }

        if (from || to) {
            queryParams.dateStart = from;
            queryParams.dateEnd = to;
        }

        if (search) {
            queryParams.search = search;
        }

        const results = await getRecords(queryParams);

        res.status(200).json({
            success: true,
            ...results
        });

    } catch (error) {
        console.error('âŒ [GET /api/notes] Error:', error);
        res.status(500).json({
            success: false,
            error: 'Failed to list notes'
        });
    }
});

/**
 * PATCH /api/notes/:noteHash
 * Update note metadata
 */
router.patch('/:noteHash', authenticateToken, async (req, res) => {
    try {
        const { noteHash } = req.params;
        const updates = req.body;

        console.log(`âœï¸ [PATCH /api/notes/${noteHash}] Updating note`);

        // TODO: Implement record update logic
        // This would involve:
        // 1. Verify user owns the note
        // 2. Update allowed fields
        // 3. Increment version/timestamp
        // 4. Re-publish to GUN

        res.status(501).json({
            success: false,
            error: 'Update endpoint not yet implemented'
        });

    } catch (error) {
        console.error('âŒ [PATCH /api/notes/:noteHash] Error:', error);
        res.status(500).json({
            success: false,
            error: 'Failed to update note'
        });
    }
});

/**
 * POST /api/notes/:noteHash/regenerate-summary
 * Regenerate summary for existing note
 */
router.post('/:noteHash/regenerate-summary', authenticateToken, async (req, res) => {
    try {
        const { noteHash } = req.params;
        const { model } = req.body;

        console.log(`ðŸ”„ [POST /api/notes/${noteHash}/regenerate-summary] Regenerating summary`);

        // TODO: Implement summary regeneration
        // 1. Fetch note and transcript
        // 2. Re-run summarization with specified model
        // 3. Update note record with new summary
        // 4. Increment summary_version

        res.status(501).json({
            success: false,
            error: 'Summary regeneration not yet implemented'
        });

    } catch (error) {
        console.error('âŒ [POST /api/notes/:noteHash/regenerate-summary] Error:', error);
        res.status(500).json({
            success: false,
            error: 'Failed to regenerate summary'
        });
    }
});

/**
 * PATCH /api/noteChunks/:localId
 * Update chunk (e.g., mark important)
 */
router.patch('/chunks/:localId', authenticateToken, async (req, res) => {
    try {
        const { localId } = req.params;
        const updates = req.body;

        console.log(`âœï¸ [PATCH /api/noteChunks/${localId}] Updating chunk`);

        // TODO: Implement chunk update logic
        // Typically used for marking chunks as important

        res.status(501).json({
            success: false,
            error: 'Chunk update endpoint not yet implemented'
        });

    } catch (error) {
        console.error('âŒ [PATCH /api/noteChunks/:localId] Error:', error);
        res.status(500).json({
            success: false,
            error: 'Failed to update chunk'
        });
    }
});

// ========================================
// Helper Functions
// ========================================

/**
 * Detect audio codec from MIME type
 * @private
 */
function _detectCodecFromMime(mimeType) {
    const codecMap = {
        'audio/mpeg': 'MP3',
        'audio/mp4': 'AAC',
        'audio/x-m4a': 'AAC',
        'audio/wav': 'PCM',
        'audio/webm': 'OPUS',
        'audio/flac': 'FLAC',
        'audio/ogg': 'VORBIS'
    };

    return codecMap[mimeType] || 'UNKNOWN';
}

// Attach helper to router for access in handlers
router._detectCodecFromMime = _detectCodecFromMime;

/**
 * Generate note title from content
 * @private
 */
function _generateNoteTitle(note_type, participants, transcriptText) {
    if (participants && participants.length > 0) {
        return `${note_type}: ${participants.join(', ')}`;
    }
    
    // Extract first few words from transcript
    const words = transcriptText.split(/\s+/).slice(0, 8).join(' ');
    return `${note_type}: ${words}...`;
}

/**
 * Get file extension from MIME type
 * @private
 */
function _getExtensionFromMime(mimeType) {
    const extMap = {
        'audio/mpeg': 'mp3',
        'audio/mp4': 'm4a',
        'audio/x-m4a': 'm4a',
        'audio/wav': 'wav',
        'audio/webm': 'webm',
        'audio/flac': 'flac',
        'audio/ogg': 'ogg'
    };

    return extMap[mimeType] || 'audio';
}

// Attach helpers to router for access in handlers
router._generateNoteTitle = _generateNoteTitle;
router._getExtensionFromMime = _getExtensionFromMime;

/**
 * POST /api/notes/converse
 * RAG (Retrieval Augmented Generation) endpoint for conversing about notes
 * Accepts a note DID and question, retrieves full context, finds related content, and generates AI response
 */
router.post('/converse', authenticateToken, async (req, res) => {
    try {
        const { 
            noteDid,
            question,
            model = 'llama3.2:3b',
            conversationHistory = [],
            includeRelated = true,
            maxRelated = 5,
            allNotes = false  // NEW: Search across all user's notes
        } = req.body;

        console.log(`\n${'='.repeat(80)}`);
        console.log(`[ALFRED Notes] Processing question${noteDid ? ` about note: ${noteDid}` : allNotes ? ' (All Notes Search)' : ' (Direct LLM mode)'}`);
        console.log(`[ALFRED Notes] Question: "${question}"`);
        console.log(`[ALFRED Notes] Model: ${model}`);
        if (allNotes) console.log(`[ALFRED Notes] Mode: Search across all notes`);
        if (allNotes === false) console.log(`[ALFRED Notes] Mode: Direct LLM (skip RAG)`);
        console.log(`${'='.repeat(80)}\n`);

        // Validate inputs
        if (!question) {
            return res.status(400).json({
                success: false,
                error: 'Question is required'
            });
        }

        const userPublicKey = req.user.publicKey || req.user.publisherPubKey;
        
        // ========================================
        // FAST PATH: Explicit Direct LLM Mode (allNotes=false)
        // ========================================
        // When allNotes is explicitly set to false, skip all RAG/classification
        // and go directly to LLM for fastest response
        if (allNotes === false && !noteDid) {
            console.log('[ALFRED Notes Fast Path] allNotes=false, going directly to LLM...');
            
            const alfredInstance = require('../helpers/alfred');
            
            const alfredOptions = {
                model: model,
                conversationHistory: conversationHistory,
                useFieldExtraction: false
            };

            const alfredResponse = await alfredInstance.query(question, alfredOptions);
            
            console.log(`[ALFRED Notes Fast Path] âœ… Response generated (${alfredResponse.answer.length} chars)`);

            return res.json({
                success: true,
                answer: alfredResponse.answer,
                context: {
                    mode: 'direct_llm',
                    fastPath: true
                },
                model: alfredResponse.model || model,
                sources: alfredResponse.sources || [],
                error: alfredResponse.error || undefined,
                error_code: alfredResponse.error_code || undefined
            });
        }
        
        // ========================================
        // MODE 1: All Notes Search (no specific noteDid)
        // ========================================
        if (!noteDid && allNotes) {
            console.log('[ALFRED Notes All Notes Mode] Extracting search parameters from question...');
            
            const alfredInstance = require('../helpers/alfred');
            
            // Use LLM to extract date range, attendee names, and primary subject from the question
            const extractionPrompt = `You are helping extract structured information from a user's question about their meeting notes.

User's question: "${question}"

Please extract the following information and respond ONLY with a JSON object (no markdown, no explanation):

{
  "dateRange": {
    "hasDate": true/false,
    "startDate": "YYYY-MM-DD" or null,
    "endDate": "YYYY-MM-DD" or null
  },
  "attendees": ["Name1", "Name2"] or [],
  "primarySubject": "main topic or subject they're asking about"
}

Rules:
- If they mention a specific date, use that for both startDate and endDate
- If they mention "last week", calculate the date range
- If they mention "yesterday", calculate that date
- If they mention "today", use today's date
- If they mention a date range like "last month", calculate the range
- If no date mentioned, set hasDate to false and dates to null
- Extract any person names mentioned as attendees
- The primarySubject should be the main topic they're asking about (2-5 words)
- Respond with ONLY the JSON object`;

            try {
                console.log('[ALFRED Notes] Calling LLM to extract search parameters...');
                
                const extractionResponse = await alfredInstance.query(extractionPrompt, {
                    model: model,
                    useFieldExtraction: false
                });
                
                console.log('[ALFRED Notes] LLM extraction response:', extractionResponse.answer);
                
                // Parse the LLM response to extract structured data
                let extractedInfo;
                try {
                    // Try to parse the response as JSON
                    const jsonMatch = extractionResponse.answer.match(/\{[\s\S]*\}/);
                    if (jsonMatch) {
                        extractedInfo = JSON.parse(jsonMatch[0]);
                    } else {
                        throw new Error('No JSON found in response');
                    }
                } catch (parseError) {
                    console.warn('[ALFRED Notes] Failed to parse LLM extraction, using defaults:', parseError.message);
                    extractedInfo = {
                        dateRange: { hasDate: false, startDate: null, endDate: null },
                        attendees: [],
                        primarySubject: question.substring(0, 50) // Use first 50 chars as fallback
                    };
                }
                
                console.log('[ALFRED Notes] Extracted info:');
                console.log(`  - Date Range: ${extractedInfo.dateRange.hasDate ? `${extractedInfo.dateRange.startDate} to ${extractedInfo.dateRange.endDate}` : 'none'}`);
                console.log(`  - Attendees: ${extractedInfo.attendees.length > 0 ? extractedInfo.attendees.join(', ') : 'none'}`);
                console.log(`  - Primary Subject: ${extractedInfo.primarySubject}`);
                
                // Build search parameters
                const searchParams = {
                    noteSearchQuery: extractedInfo.primarySubject,
                    user: req.user,
                    isAuthenticated: true,
                    limit: 10
                };
                
                // Add date filtering if dates were extracted
                if (extractedInfo.dateRange.hasDate) {
                    if (extractedInfo.dateRange.startDate) {
                        // Convert to Unix timestamp (start of day)
                        const startDate = new Date(extractedInfo.dateRange.startDate + 'T00:00:00Z');
                        searchParams.dateStart = Math.floor(startDate.getTime() / 1000);
                    }
                    if (extractedInfo.dateRange.endDate) {
                        // Convert to Unix timestamp (end of day)
                        const endDate = new Date(extractedInfo.dateRange.endDate + 'T23:59:59Z');
                        searchParams.dateEnd = Math.floor(endDate.getTime() / 1000);
                    }
                }
                
                // Add attendee filtering if attendees were extracted
                if (extractedInfo.attendees.length > 0) {
                    searchParams.noteAttendees = extractedInfo.attendees.join(',');
                }
                
                console.log('[ALFRED Notes] Searching notes with parameters:', searchParams);
                
                // Search for matching notes
                const searchResults = await getRecords(searchParams);
                
                console.log(`[ALFRED Notes] Found ${searchResults.searchResults} matching notes`);
                
                if (searchResults.searchResults === 0) {
                    return res.json({
                        success: true,
                        answer: `I couldn't find any notes matching your search criteria. ${extractedInfo.dateRange.hasDate ? `I looked for notes from ${extractedInfo.dateRange.startDate} to ${extractedInfo.dateRange.endDate}` : 'Try providing a date range or more specific details about the meeting.'} ${extractedInfo.attendees.length > 0 ? `with attendees: ${extractedInfo.attendees.join(', ')}` : ''}`,
                        context: {
                            mode: 'allNotes',
                            searchQuery: extractedInfo.primarySubject,
                            dateRange: extractedInfo.dateRange,
                            attendees: extractedInfo.attendees,
                            resultsFound: 0
                        },
                        model: model,
                        sources: []
                    });
                }
                
                // Get the top-ranked note
                const topNote = searchResults.records[0];
                const topNoteDid = topNote.did;
                const searchScores = topNote.searchScores;
                
                console.log('[ALFRED Notes] Top note selected:', topNote.data?.basic?.name);
                console.log(`  - DID: ${topNoteDid}`);
                console.log(`  - Final Score: ${searchScores.finalScore}`);
                console.log(`  - Chunk Score: ${searchScores.chunkScore} (${searchScores.chunkCount} chunks)`);
                console.log(`  - Attendee Score: ${searchScores.attendeeScore} (${searchScores.attendeeMatches} matches)`);
                
                // Now proceed to RAG mode with the top note
                // We'll use the existing RAG logic below by setting noteDid
                // and falling through to the RAG section
                console.log('[ALFRED Notes] Proceeding to RAG mode with top-ranked note...');
                
                // Override noteDid with the top result and continue to RAG mode below
                req.body.noteDid = topNoteDid;
                
                // Add search context to be included in the response
                req.searchContext = {
                    mode: 'allNotes',
                    searchQuery: extractedInfo.primarySubject,
                    dateRange: extractedInfo.dateRange,
                    attendees: extractedInfo.attendees,
                    totalResults: searchResults.searchResults,
                    topNoteScore: searchScores
                };
                
                // Continue to RAG mode with the selected note
                // (Don't return here, let it fall through to the RAG logic below)
                
            } catch (error) {
                console.error('[ALFRED Notes] Error in all notes search:', error);
                return res.status(500).json({
                    success: false,
                    error: 'Failed to search notes',
                    details: error.message
                });
            }
        }
        
        // ========================================
        // MODE 2: Pure LLM Mode (no noteDid, no allNotes)
        // ========================================
        if (!req.body.noteDid && !allNotes) {
            console.log('[ALFRED Notes] Running in pure LLM mode (no note context)');
            
            const alfredInstance = require('../helpers/alfred');
            
            const alfredOptions = {
                model: model,
                conversationHistory: conversationHistory,
                useFieldExtraction: false
            };

            const alfredResponse = await alfredInstance.query(question, alfredOptions);
            
            console.log(`[ALFRED Notes] âœ… Response generated (${alfredResponse.answer.length} chars)`);

            return res.json({
                success: true,
                answer: alfredResponse.answer,
                context: {
                    mode: 'llm'
                },
                model: alfredResponse.model || model,
                sources: alfredResponse.sources || [],
                error: alfredResponse.error || undefined,
                error_code: alfredResponse.error_code || undefined
            });
        }

        // ========================================
        // MODE 3: RAG Mode with Specific Note
        // ========================================
        // Get the noteDid (either from request or from allNotes search above)
        const targetNoteDid = req.body.noteDid;
        
        // Step 1: Retrieve the main note record with resolveDepth=1 to include transcript
        console.log('[ALFRED Notes RAG Mode] Step 1: Fetching note record with embedded references...');
        const noteResults = await getRecords({
            source: 'gun',
            did: targetNoteDid,
            limit: 1,
            resolveDepth: 1,  // Resolve nested references (transcript, chunks)
            user: req.user,
            isAuthenticated: true
        });

        if (!noteResults.records || noteResults.records.length === 0) {
            return res.status(404).json({
                success: false,
                error: 'Note not found'
            });
        }

        const noteRecord = noteResults.records[0];
        const noteData = noteRecord.data?.notes || {};
        const noteBasic = noteRecord.data?.basic || {};
        
        console.log(`[ALFRED Notes RAG] âœ… Found note: "${noteBasic.name}"`);

        // Step 2: Extract the full transcript (already embedded with resolveDepth=1)
        let transcriptText = '';
        const transcriptData = noteData.transcript_full_text;
        
        if (transcriptData) {
            console.log('[ALFRED Notes RAG] Step 2: Extracting embedded transcript...');
            
            // Check if transcript is already resolved (embedded object)
            if (typeof transcriptData === 'object' && transcriptData.data?.text?.value) {
                transcriptText = transcriptData.data.text.value;
                console.log(`[ALFRED Notes RAG] âœ… Extracted embedded transcript (${transcriptText.length} chars)`);
            } 
            // Fallback: if it's just a DID string, fetch it separately
            else if (typeof transcriptData === 'string') {
                try {
                    const transcriptResults = await getRecords({
                        source: 'gun',
                        did: transcriptData,
                        limit: 1,
                        user: req.user,
                        isAuthenticated: true
                    });
                    
                    if (transcriptResults.records && transcriptResults.records.length > 0) {
                        transcriptText = transcriptResults.records[0].data?.text?.value || '';
                        console.log(`[ALFRED Notes RAG] âœ… Fetched transcript separately (${transcriptText.length} chars)`);
                    }
                } catch (error) {
                    console.warn('[ALFRED Notes RAG] âš ï¸ Failed to fetch transcript:', error.message);
                }
            }
        }

        // Step 3: Retrieve all note chunks (if not already empty/missing)
        const chunkDids = noteData.chunk_ids || [];
        let chunks = [];
        
        if (chunkDids.length > 0) {
            console.log(`[ALFRED Notes RAG] Step 3: Fetching ${chunkDids.length} chunks...`);
            try {
                // Check if first item is already an object (resolved via resolveDepth)
                if (typeof chunkDids[0] === 'object' && chunkDids[0].data) {
                    // Chunks are already embedded
                    chunks = chunkDids;
                    console.log(`[ALFRED Notes RAG] âœ… Using ${chunks.length} embedded chunks`);
                } else {
                    // Chunks are DIDs, need to fetch them
                    const chunkPromises = chunkDids.map(chunkDid =>
                        getRecords({
                            source: 'gun',
                            did: chunkDid,
                            limit: 1,
                            user: req.user,
                            isAuthenticated: true
                        })
                    );
                    
                    const chunkResults = await Promise.all(chunkPromises);
                    chunks = chunkResults
                        .filter(result => result.records && result.records.length > 0)
                        .map(result => result.records[0]);
                    
                    console.log(`[ALFRED Notes RAG] âœ… Retrieved ${chunks.length} chunks`);
                }
            } catch (error) {
                console.warn('[ALFRED Notes RAG] âš ï¸ Failed to fetch chunks:', error.message);
            }
        } else {
            console.log('[ALFRED Notes RAG] Step 3: No chunks found (chunk_ids is empty)');
        }

        // Step 4: Find related notes and chunks using tags
        let relatedContent = [];
        
        if (includeRelated && noteBasic.tagItems && noteBasic.tagItems.length > 0) {
            console.log(`[ALFRED Notes RAG] Step 4: Finding related content using tags: ${noteBasic.tagItems.join(', ')}`);
            
            try {
                // Search for related note chunks
                const relatedChunksResults = await getRecords({
                    source: 'gun',
                    recordType: 'noteChunks',
                    tags: noteBasic.tagItems.join(','),
                    limit: maxRelated,
                    user: req.user,
                    isAuthenticated: true
                });
                
                if (relatedChunksResults.records && relatedChunksResults.records.length > 0) {
                    // Filter out chunks from the current note
                    const otherChunks = relatedChunksResults.records.filter(chunk => 
                        chunk.data?.noteChunks?.note_ref !== noteDid
                    );
                    
                    relatedContent.push(...otherChunks);
                    console.log(`[ALFRED Notes RAG] âœ… Found ${otherChunks.length} related chunks from other notes`);
                }

                // Search for related notes
                const relatedNotesResults = await getRecords({
                    source: 'gun',
                    recordType: 'notes',
                    tags: noteBasic.tagItems.join(','),
                    limit: maxRelated,
                    user: req.user,
                    isAuthenticated: true
                });
                
                if (relatedNotesResults.records && relatedNotesResults.records.length > 0) {
                    // Filter out the current note
                    const otherNotes = relatedNotesResults.records.filter(note => 
                        note.did !== noteDid
                    );
                    
                    relatedContent.push(...otherNotes);
                    console.log(`[ALFRED Notes RAG] âœ… Found ${otherNotes.length} related notes`);
                }
            } catch (error) {
                console.warn('[ALFRED Notes RAG] âš ï¸ Failed to fetch related content:', error.message);
            }
        }

        // Step 5: Build comprehensive context
        console.log('[ALFRED Notes RAG] Step 5: Building context for ALFRED...');
        
        const context = {
            currentNote: {
                title: noteBasic.name,
                type: noteData.note_type,
                date: new Date(noteData.created_at).toISOString(),
                participants: noteData.participant_display_names || [],
                roles: noteData.participant_roles || [],
                tags: noteBasic.tagItems || [],
                summary: {
                    key_points: noteData.summary_key_points || [],
                    decisions: noteData.summary_decisions || [],
                    action_items: {
                        texts: noteData.summary_action_item_texts || [],
                        assignees: noteData.summary_action_item_assignees || [],
                        due_dates: noteData.summary_action_item_due_texts || []
                    },
                    open_questions: noteData.summary_open_questions || []
                },
                topics: noteData.topics_auto || [],
                keywords: noteData.keywords_auto || [],
                sentiment: noteData.sentiment_overall || 'NEUTRAL'
            },
            transcript: transcriptText,
            chunks: chunks.map(chunk => ({
                index: chunk.data?.noteChunks?.chunk_index,
                text: chunk.data?.noteChunks?.text,
                time_range: {
                    start_ms: chunk.data?.noteChunks?.start_time_ms,
                    end_ms: chunk.data?.noteChunks?.end_time_ms
                },
                tags: chunk.data?.basic?.tagItems || []
            })),
            relatedContent: relatedContent.slice(0, maxRelated).map(item => {
                if (item.recordType === 'noteChunks') {
                    return {
                        type: 'chunk',
                        text: item.data?.noteChunks?.text,
                        tags: item.data?.basic?.tagItems || [],
                        from_note: item.data?.noteChunks?.note_ref
                    };
                } else if (item.recordType === 'notes') {
                    return {
                        type: 'note',
                        title: item.data?.basic?.name,
                        summary: item.data?.notes?.summary_key_points?.slice(0, 3) || [],
                        tags: item.data?.basic?.tagItems || [],
                        did: item.did
                    };
                }
                return null;
            }).filter(Boolean)
        };

        console.log('[ALFRED Notes RAG] Context built:');
        console.log(`  - Transcript: ${transcriptText.length} chars`);
        console.log(`  - Chunks: ${chunks.length}`);
        console.log(`  - Related content: ${relatedContent.length} items`);

        // Step 6: Prepare ALFRED query with note-specific context
        const alfredInstance = require('../helpers/alfred');
        
        // Build a comprehensive context string that includes all note information
        const contextString = `You are answering questions about a specific meeting note.

Note Title: ${context.currentNote.title}
Note Type: ${context.currentNote.type}
Date: ${context.currentNote.date}
${context.currentNote.participants.length > 0 ? `Participants: ${context.currentNote.participants.join(', ')}` : ''}

${context.currentNote.summary.key_points.length > 0 ? `Key Points from Summary:
${context.currentNote.summary.key_points.map((point, i) => `${i + 1}. ${point}`).join('\n')}` : ''}

${context.currentNote.summary.decisions.length > 0 ? `Decisions Made:
${context.currentNote.summary.decisions.map((decision, i) => `${i + 1}. ${decision}`).join('\n')}` : ''}

${context.currentNote.summary.action_items.texts.length > 0 ? `Action Items:
${context.currentNote.summary.action_items.texts.map((text, i) => 
    `${i + 1}. ${text} (Assignee: ${context.currentNote.summary.action_items.assignees[i]}, Due: ${context.currentNote.summary.action_items.due_dates[i]})`
).join('\n')}` : ''}

${transcriptText ? `Full Transcript:
${transcriptText}` : ''}

${context.relatedContent.length > 0 ? `Related Content from Other Notes:
${context.relatedContent.map((item, i) => {
    if (item.type === 'chunk') {
        return `${i + 1}. [Chunk] ${item.text.substring(0, 200)}... (Tags: ${item.tags.join(', ')})`;
    } else {
        return `${i + 1}. [Note] ${item.title} - ${item.summary.join('; ')}`;
    }
}).join('\n')}` : ''}`;

        console.log('[ALFRED Notes RAG] Step 6: Calling ALFRED for response...');
        console.log(`[ALFRED Notes RAG] Context string length: ${contextString.length} chars`);
        
        // Call ALFRED with the pre-formatted context string
        // By passing pinnedJsonData AND existingContext, the existingContext will be used as the prompt context
        const alfredOptions = {
            model: model,
            conversationHistory: conversationHistory,
            pinnedJsonData: context, // Pass structured context (for metadata)
            existingContext: contextString, // Pass formatted context string (for LLM prompt)
            useFieldExtraction: true
        };

        const alfredResponse = await alfredInstance.query(question, alfredOptions);
        
        console.log(`[ALFRED Notes RAG] âœ… Response generated (${alfredResponse.answer.length} chars)`);

        // Return the response
        const responseContext = {
                note: {
                did: targetNoteDid,
                    title: context.currentNote.title,
                    type: context.currentNote.type
                },
                chunks_count: chunks.length,
                related_content_count: relatedContent.length,
                transcript_length: transcriptText.length
        };
        
        // If this came from an allNotes search, include the search context
        if (req.searchContext) {
            responseContext.search = req.searchContext;
        }
        
        res.json({
            success: true,
            answer: alfredResponse.answer,
            context: responseContext,
            model: alfredResponse.model || model,
            sources: alfredResponse.sources || [],
            // Include error info if present (e.g., Ollama unavailable)
            error: alfredResponse.error || undefined,
            error_code: alfredResponse.error_code || undefined
        });

    } catch (error) {
        console.error('[ALFRED Notes RAG] âŒ Error:', error);
        
        // Provide specific error messages for common issues
        let errorMessage = 'Failed to process question about note';
        let errorDetails = error.message;
        
        if (error.message.includes('Ollama') || error.code === 'ECONNREFUSED') {
            errorMessage = 'AI service unavailable';
            errorDetails = 'Ollama is not running. Please start it with: make backend-only';
        }
        
        res.status(500).json({
            success: false,
            error: errorMessage,
            details: errorDetails,
            error_code: error.code
        });
    }
});

module.exports = router;

