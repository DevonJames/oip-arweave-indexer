services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"      
      - xpack.security.enabled=false
      # Reduce log verbosity - only show warnings and errors
      - logger.level=WARN
      - logger.org.elasticsearch=WARN
      - logger.root=WARN
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      # Bind mount to host filesystem instead of Docker-managed volume
      # This prevents hitting Docker's disk image space limits
      # Set ELASTICSEARCH_DATA_PATH in .env to customize location (default: ./elasticsearch_data)
      - ${ELASTICSEARCH_DATA_PATH:-./elasticsearch_data}:/usr/share/elasticsearch/data
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
      - "${ELASTICSEARCH_TRANSPORT_PORT:-9300}:9300"
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-monolithic
      - standard
      - standard-macMseries
      - minimal
      - minimal-with-scrape
      - gpu
      - standard-gpu
      - max-decentralized
      - max-decentralized-gpu

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.8
    depends_on:
      - elasticsearch
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    environment:
      - ELASTICCLIENTHOST=http://elasticsearch:9200
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-monolithic
      - standard
      - standard-macMseries
      - minimal
      - minimal-with-scrape
      - gpu
      - standard-gpu
      - max-decentralized
      - max-decentralized-gpu

  ipfs:
    image: ipfs/go-ipfs:latest
    environment:
      - IPFS_PROFILE=server
    ports:
      - "${IPFS_SWARM_PORT:-4001}:4001"
      - "${IPFS_API_PORT:-5001}:5001"
      - "${IPFS_GATEWAY_PORT:-8080}:8080"
    volumes:
      - ipfsdata:/data/ipfs
    networks:
      - oip-network
    profiles:
      - standard-monolithic
      - standard
      - standard-macMseries
      - standard-gpu
      - max-decentralized
      - max-decentralized-gpu

  # Standard OIP service (for distributed deployments with AI features)
  oip:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "${PORT:-3005}:${PORT:-3005}"
      - "${DEBUG_PORT:-9229}:9229"
    volumes:
      - ./data:/usr/src/app/data  # Media files and other data
      - ./helpers:/usr/src/app/helpers
      - ./routes:/usr/src/app/routes
      - ./voices:/usr/src/app/voices
      - ../public:/usr/src/parent-public:ro  # Mount parent directory's public folder
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=${NODE_OPTIONS}
      - ELASTICSEARCH_HOST=${ELASTICSEARCHHOST}
      - ELASTICCLIENTUSERNAME=${ELASTICCLIENTUSERNAME}
      - ELASTICCLIENTPASSWORD=${ELASTICCLIENTPASSWORD}
      - STT_SERVICE_URL=http://stt-service:8003
      - TTS_SERVICE_URL=http://tts-service:8005
    depends_on:
      - elasticsearch
      - tts-service
      - stt-service
      - ollama
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard
      - standard-macMseries
      - max-decentralized

  # Minimal OIP service (core functionality only, no AI dependencies, no canvas)
  oip-minimal:
    build:
      context: .
      dockerfile: Dockerfile-minimal
    env_file:
      - .env
    ports:
      - "${PORT:-3005}:${PORT:-3005}"
      - "${DEBUG_PORT:-9229}:9229"
    volumes:
      - ./data:/usr/src/app/data  # Media files and other data
      - ./helpers:/usr/src/app/helpers
      - ./routes:/usr/src/app/routes
      - ./voices:/usr/src/app/voices
      - ../public:/usr/src/parent-public:ro  # Mount parent directory's public folder
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=${NODE_OPTIONS}
      - ELASTICSEARCH_HOST=${ELASTICSEARCHHOST}
      - ELASTICCLIENTUSERNAME=${ELASTICCLIENTUSERNAME}
      - ELASTICCLIENTPASSWORD=${ELASTICCLIENTPASSWORD}
    depends_on:
      - elasticsearch
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - minimal

  # Minimal OIP service with scraping capabilities (includes canvas)
  oip-minimal-with-scrape:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "${PORT:-3005}:${PORT:-3005}"
      - "${DEBUG_PORT:-9229}:9229"
    volumes:
      - ./data:/usr/src/app/data  # Media files and other data
      - ./helpers:/usr/src/app/helpers
      - ./routes:/usr/src/app/routes
      - ./voices:/usr/src/app/voices
      - ../public:/usr/src/parent-public:ro  # Mount parent directory's public folder
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=${NODE_OPTIONS}
      - ELASTICSEARCH_HOST=${ELASTICSEARCHHOST}
      - ELASTICCLIENTUSERNAME=${ELASTICCLIENTUSERNAME}
      - ELASTICCLIENTPASSWORD=${ELASTICCLIENTPASSWORD}
    depends_on:
      - elasticsearch
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - minimal-with-scrape

  # Standard monolithic OIP service (all services in one container)
  oip-full:
    build:
      context: .
      dockerfile: Dockerfile-full
    env_file:
      - .env
    ports:
      - "${PORT:-3005}:${PORT:-3005}"
      - "${DEBUG_PORT:-9229}:9229"
      - "${TEXT_GENERATOR_PORT:-8081}:8081"  # Text generator
      - "${SPEECH_SYNTHESIZER_PORT:-8082}:8082"  # Speech synthesizer
      - "${NGROK_DASHBOARD_PORT:-4040}:4040"  # Ngrok dashboard
    volumes:
      - ./data:/usr/src/app/data  # Media files and other data
      - ./helpers:/usr/src/app/helpers
      - ./routes:/usr/src/app/routes
      - ../public:/usr/src/parent-public:ro  # Mount parent directory's public folder
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=${NODE_OPTIONS}
      - ELASTICSEARCH_HOST=${ELASTICSEARCHHOST}
      - ELASTICCLIENTUSERNAME=${ELASTICCLIENTUSERNAME}
      - ELASTICCLIENTPASSWORD=${ELASTICCLIENTPASSWORD}
      - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN}
    depends_on:
      - elasticsearch
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-monolithic

  # GPU-optimized OIP service
  oip-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "${NEXT_FRONTEND_PORT:-3000}:3000"  # Next.js frontend
      - "${PORT:-3005}:${PORT:-3005}"  # Express API
      - "${DEBUG_PORT:-9229}:9229"
    volumes:
      - ./data:/usr/src/app/data  # Media files and other data
      - ./helpers:/usr/src/app/helpers
      - ./routes:/usr/src/app/routes
      - ./voices:/usr/src/app/voices
      - ../public:/usr/src/parent-public:ro  # Mount parent directory's public folder
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=${NODE_OPTIONS}
      - ELASTICSEARCH_HOST=${ELASTICSEARCHHOST}
      - ELASTICCLIENTUSERNAME=${ELASTICCLIENTUSERNAME}
      - ELASTICCLIENTPASSWORD=${ELASTICCLIENTPASSWORD}
      - STT_SERVICE_URL=http://stt-service-gpu:8003
      - TTS_SERVICE_URL=http://tts-service-gpu:5002
      - OLLAMA_HOST=http://ollama-gpu:11434  # Internal Docker network port stays 11434
      - DEFAULT_LLM_MODEL=llama3.2:3b
    depends_on:
      - elasticsearch
      - ollama-gpu
      - tts-service-gpu
      - stt-service-gpu
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - gpu
      - oip-gpu-only
      - standard-gpu
      - max-decentralized-gpu

  # Self-hosted Speech Synthesizer (Coqui TTS) - for distributed deployments
  speech-synthesizer:
    build:
      context: ./speech-synthesizer
      dockerfile: Dockerfile
    ports:
      - "${SPEECH_SYNTHESIZER_PORT:-8082}:8082"
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard
      - standard-macMseries
      - max-decentralized

  # GPU-accelerated TTS Service (Neural Models with CUDA)
  tts-service-gpu:
    build:
      context: ./text-to-speech
      dockerfile: Dockerfile.gpu
    ports:
      - "${TTS_SERVICE_PORT:-5002}:5002"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - TTS_GPU_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - gpu
      - standard-gpu
      - max-decentralized-gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Ollama LLM service for standard deployments (CPU/Apple Silicon)
  ollama:
    image: ollama/ollama:latest
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ./ollama_data:/root/.ollama  # Persistent model storage
    networks:
      - oip-network
    restart: unless-stopped
    dns:
      - 8.8.8.8
      - 8.8.4.4
    profiles:
      - standard
      - standard-macMseries
      - standard-monolithic
      - max-decentralized

  # Ollama LLM service for GPU deployments (NVIDIA CUDA)
  ollama-gpu:
    image: ollama/ollama:latest
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ./ollama_data:/root/.ollama  # Persistent model storage
    networks:
      - oip-network
    restart: unless-stopped
    dns:
      - 8.8.8.8
      - 8.8.4.4
    profiles:
      - standard-gpu
      - gpu
      - max-decentralized-gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Text generator for standard deployments (CPU/Apple Silicon)
  text-generator:
    build: ./text-generator
    env_file:
      - .env
    environment:
      - OLLAMA_HOST=http://ollama:11434  # Internal Docker network port stays 11434
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    ports:
      - "${TEXT_GENERATOR_PORT:-8081}:8081"
    depends_on:
      - ollama
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard
      - standard-macMseries
      - standard-monolithic
      - max-decentralized

  # Speech-to-Text Service (Whisper)
  stt-service:
    build: ./speech-to-text
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-base}
      - WHISPER_DEVICE=${WHISPER_DEVICE:-cpu}
      - WHISPER_COMPUTE_TYPE=${WHISPER_COMPUTE_TYPE:-int8}
    ports:
      - "${STT_SERVICE_PORT:-8003}:8003"
    volumes:
      - whisper_models:/app/models
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-monolithic
      - standard
      - standard-macMseries
      - max-decentralized

  # GPU-accelerated Speech-to-Text Service (Whisper with CUDA)
  stt-service-gpu:
    build:
      context: ./speech-to-text
      dockerfile: Dockerfile.gpu
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-base}
      - WHISPER_DEVICE=${WHISPER_DEVICE:-cuda}
      - CUDA_VISIBLE_DEVICES=0
    ports:
      - "${STT_SERVICE_PORT:-8003}:8003"
    volumes:
      - whisper_models:/app/models
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-gpu
      - gpu
      - max-decentralized-gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Text-to-Speech Service (Multi-engine)
  tts-service:
    build: ./text-to-speech
    ports:
      - "${TTS_SERVICE_PORT:-8005}:8005"  # Standard port for TTS service
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-monolithic
      - standard
      - standard-macMseries
      - max-decentralized

  # Ngrok for public access - DISABLED: Using Makefile ngrok with custom domain instead
  # ngrok:
  #   image: ngrok/ngrok
  #   command: ["ngrok", "http", "oip:3005", "--log=stdout"]
  #   environment:
  #     - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN}
  #   depends_on:
  #     - oip
  #   ports:
  #     - "4040:4040"
  #   networks:
  #     - oip-network
  #   restart: unless-stopped
  #   profiles:
  #     - standard
  
  # Ngrok for public access
  ngrok:
    image: ngrok/ngrok
    command: http --domain=${NGROK_DOMAIN} oip:${PORT:-3005}
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN}
    depends_on:
      - oip
    ports:
      - "${NGROK_DASHBOARD_PORT:-4040}:4040"
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard
      - standard-macMseries
      - max-decentralized

  # Ngrok for minimal profile
  ngrok-minimal:
    image: ngrok/ngrok
    command: http --domain=${NGROK_DOMAIN} oip-minimal:${PORT:-3005}
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN}
    depends_on:
      - oip-minimal
    ports:
      - "${NGROK_DASHBOARD_PORT:-4040}:4040"
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - minimal

  # Ngrok for GPU deployments - Uses configurable domain from .env
  ngrok-gpu:
    image: ngrok/ngrok:latest
    command: http --domain=${NGROK_DOMAIN} oip-gpu:${PORT:-3005}
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN}
    depends_on:
      - oip-gpu
    ports:
      - "${NGROK_DASHBOARD_PORT:-4040}:4040"  # Use configurable port to avoid conflicts
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - standard-gpu
      - max-decentralized-gpu

  # GUN Relay Service for private/temporary storage with multi-node sync support
  gun-relay:
    image: node:18-alpine
    working_dir: /app
    command: sh -c "npm init -y >/dev/null 2>&1 && npm i gun && node gun-relay-server.js"
    ports:
      - "${GUN_RELAY_PORT:-8765}:8765"
    volumes:
      - gundata:/app/data
      - ./gun-relay-server.js:/app/gun-relay-server.js:ro
    environment:
      # Configure GUN peers for multi-node synchronization
      - GUN_PEERS=${GUN_EXTERNAL_PEERS:-}
      - GUN_ENV=production
      - GUN_SYNC_ENABLED=true
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - minimal
      - minimal-with-scrape
      - standard
      - standard-macMseries
      - standard-gpu
      - standard-monolithic
      - max-decentralized
      - max-decentralized-gpu

  # AR.IO Gateway - Local Arweave gateway with GraphQL support
  # Provides local access to Arweave network data with minimal storage (cache on demand)
  # Exposes GraphQL endpoint at /graphql for local searches
  # Note: AR.IO gateway caches data on demand - it doesn't need to sync all blocks
  # If you see block importing logs, it's indexing metadata, not storing all data
  ario-gateway:
    image: ghcr.io/ar-io/ar-io-core:latest
    env_file:
      - .env
    ports:
      # External port configurable via ARIO_GATEWAY_PORT env var (default: 4000)
      # Internal port always 4000 (AR.IO gateway container expects port 4000)
      - "${ARIO_GATEWAY_PORT:-4000}:4000"
    volumes:
      # Bind mount to host filesystem for cache/data persistence
      # Set ARIO_GATEWAY_DATA_PATH in .env to customize location (default: ./ario_gateway_data)
      # IMPORTANT: AR.IO gateway stores data in /app/data (not /data)
      # If START_HEIGHT isn't working, the gateway may have a database that stores
      # the last synced block. Delete ALL files in this directory including hidden .db files
      - ${ARIO_GATEWAY_DATA_PATH:-./ario_gateway_data}:/app/data
    environment:
      # AR.IO gateway configuration
      # Internal container port is always 4000 (AR.IO gateway expects this)
      - PORT=4000
      # Enable GraphQL endpoint for local searches
      - GRAPHQL_ENABLED=true
      # START_HEIGHT: Explicitly pass from .env (Docker Compose reads .env for variable substitution)
      # Set START_HEIGHT=1463750 in your .env file
      # Using ${START_HEIGHT} so Docker Compose substitutes it from .env at compose time
      # START_HEIGHT only applies on FIRST SYNC - if gateway has existing data,
      # it will continue from where it left off. Delete data directory to reset.
      - START_HEIGHT=${START_HEIGHT}
    networks:
      - oip-network
    restart: unless-stopped
    profiles:
      - max-decentralized
      - max-decentralized-gpu
    healthcheck:
      # Healthcheck uses internal port 4000 (container port, not host port)
      test: ["CMD", "curl", "-f", "http://localhost:4000/ar-io/info"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  oip-network:
    name: ${COMPOSE_PROJECT_NAME:-oip-arweave-indexer}_oip-network
    driver: bridge

volumes:
  # Note: esdata removed - now using bind mount to host filesystem (see elasticsearch service)
  # This prevents hitting Docker's disk image space limits
  ipfsdata:
    name: ${COMPOSE_PROJECT_NAME:-oip-arweave-indexer}_ipfsdata
  whisper_models:
    name: ${COMPOSE_PROJECT_NAME:-oip-arweave-indexer}_whisper_models
  gundata:
    name: ${COMPOSE_PROJECT_NAME:-oip-arweave-indexer}_gundata
