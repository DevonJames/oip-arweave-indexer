version: "3.8"

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - oip-network
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.8
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    environment:
      - ELASTICCLIENTHOST=http://elasticsearch:9200
    networks:
      - oip-network
    restart: unless-stopped

  ipfs:
    image: ipfs/go-ipfs:latest
    environment:
      - IPFS_PROFILE=server
    ports:
      - "4001:4001"
      - "5001:5001"
      - "8080:8080"
    volumes:
      - ipfsdata:/data/ipfs
    networks:
      - oip-network
    restart: unless-stopped

  oip:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "3005:3005"
      - "9229:9229"
    volumes:
      - ./media/jfk:/usr/src/app/media/jfk
    environment:
      - NODE_ENV=production
      - ELASTICSEARCH_HOST=${ELASTICSEARCHHOST}
      - ELASTICCLIENTUSERNAME=${ELASTICCLIENTUSERNAME}
      - ELASTICCLIENTPASSWORD=${ELASTICCLIENTPASSWORD}
    depends_on:
      - elasticsearch
    networks:
      oip-network:
        aliases:
          - oiparweave
    restart: unless-stopped

  # Self-hosted Text Generation (LLaMA2)
  text-generator:
    build:
      context: ./text-generator
      dockerfile: Dockerfile
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    runtime: nvidia
    deploy:
      resources:
        limits:
          cpus: "16"
          memory: "120g"
        reservations:
          cpus: "8"
          memory: "64g"
    ports:
      - "8081:8081"
    networks:
      - oip-network
    restart: unless-stopped

  # Self-hosted Speech Synthesizer (Coqui TTS)
  speech-synthesizer:
    build:
      context: ./speech-synthesizer
      dockerfile: Dockerfile
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    runtime: nvidia
    deploy:
      resources:
        limits:
          cpus: "16"
          memory: "120g"
        reservations:
          cpus: "8"
          memory: "64g"
    ports:
      - "8082:8082"
    networks:
      - oip-network
    restart: unless-stopped

  # Ngrok for public access
  ngrok:
    image: ngrok/ngrok
    command: http oip:3005
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN}
    ports:
      - "4040:4040"
    depends_on:
      - oip
    networks:
      - oip-network
    restart: unless-stopped

  # Bisq Daemon for exchange functionality
  bisq:
    build:
      context: ./bisq-daemon
      dockerfile: Dockerfile
    ports:
      - "9998:9998"
    volumes:
      - bisq-data:/root/.local/share/Bisq
    environment:
      - BISQ_APP_NAME=bisq-daemon
      - BISQ_HOME=/root/.local/share/Bisq
    networks:
      - oip-network

networks:
  oip-network:
    driver: bridge

volumes:
  esdata:
  ipfsdata:
  bisq-data: